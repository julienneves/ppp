
@article{dufour_monte_2006,
  title = {Monte {{Carlo}} Tests with Nuisance Parameters: {{A}} General Approach to Finite-Sample Inference and Nonstandard Asymptotics},
  volume = {133},
  shorttitle = {Monte {{Carlo}} Tests with Nuisance Parameters},
  abstract = {The technique of Monte Carlo (MC) tests [Dwass (1957), Barnard (1963)] provides an attractive method of building exact tests from statistics whose finite sample distribution is intractable but can be simulated (provided it does not involve nuisance parameters). We extend this method in two ways: first, by allowing for MC tests based on exchangeable possibly discrete test statistics; second, by generalizing the method to statistics whose null distributions involve nuisance parameters (maximized MC tests, MMC). Simplified asymptotically justified versions of the MMC method are also proposed and it is shown that they provide a simple way of improving standard asymptotics and dealing with nonstandard asymptotics (e.g., unit root asymptotics). Parametric bootstrap tests may be interpreted as a simplified version of the MMC method (without the general validity properties of the latter).$<$P$>$(This abstract was borrowed from another version of this item.)},
  timestamp = {2016-08-01T22:10:46Z},
  number = {2},
  urldate = {2016-07-29},
  journal = {Journal of Econometrics},
  author = {Dufour, Jean-Marie},
  year = {2006},
  pages = {443--477},
  file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\HFQRWTDN\\v133y2006i2p443-477.html:text/html}
}

@article{haldrup_robustness_2002,
  title = {On the {{Robustness}} of {{Unit Root Tests}} in the {{Presence}} of {{Double Unit Roots}}},
  volume = {23},
  issn = {1467-9892},
  doi = {10.1111/1467-9892.00260},
  timestamp = {2016-08-26T17:19:45Z},
  number = {2},
  journal = {Journal of Time Series Analysis},
  author = {Haldrup, Niels and Lildholdt, Peter},
  year = {2002},
  keywords = {Dickey–Fuller test,I(1) versus I(2),Phillips–Perron test,Unit root tests},
  pages = {155--171}
}

@article{dufour_wald_2013,
  title = {Wald Tests When Restrictions Are Locally Singular},
  abstract = {Wald-type tests are convenient because they allow one to test a wide array of linear and nonlinear restrictions from a single unrestricted estimator; we focus on the problem of implementing Wald-type tests for nonlinear restrictions. We provide examples showing that Wald statistics in non-regular cases can have several asymptotic distributions; the usual critical values based on a chi-square distribution can both lead to under-rejections and over-rejections; indeed, the Wald statistic may diverge under the null hypothesis. We study the asymptotic distribution of Wald-type statistics for the class of polynomial restrictions and show that the Wald statistic either has a non-degenerate asymptotic distribution, or diverges to infinity. We provide conditions for convergence and a general characterization of this distribution. We provide bounds on the asymptotic distribution (when it exists). In several cases of interest, this bound yields an easily available conservative critical value. We propose an adaptive consistent strategy for determining whether the asymptotic distribution exists and which form it takes.},
  timestamp = {2016-07-30T01:33:56Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.0569},
  primaryClass = {math, stat},
  urldate = {2016-07-29},
  journal = {arXiv:1312.0569 [math, stat]},
  author = {Dufour, Jean-Marie and Renault, Eric and Zinde-Walsh, Victoria},
  month = dec,
  year = {2013},
  keywords = {62FO3,Mathematics - Statistics Theory},
  file = {arXiv\:1312.0569 PDF:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\3B58HVVV\\Dufour et al. - 2013 - Wald tests when restrictions are locally singular.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\FNZV6TQF\\1312.html:text/html}
}

@incollection{dufour_monte_2003,
  title = {Monte {{Carlo Test Methods}} in {{Econometrics}}},
  copyright = {Copyright \textcopyright{} 2001, 2003 by Blackwell Publishing Ltd},
  isbn = {978-0-470-99624-9},
  abstract = {This chapter contains section titled:

* INTRODUCTION
* STATISTICAL ISSUES: A PRACTICAL APPROACH TO CORE QUESTIONS
* THE MONTE CARLO TEST TECHNIQUE: AN EXACT RANDOMIZED TEST PROCEDURE * MONTE CARLO TESTS: ECONOMETRIC APPLICATIONS
* CONCLUSION},
  language = {en},
  timestamp = {2016-08-01T22:10:40Z},
  urldate = {2016-07-29},
  booktitle = {A {{Companion}} to {{Theoretical Econometrics}}},
  publisher = {{Blackwell Publishing Ltd}},
  author = {Dufour, Jean-Marie and Khalaf, Lynda},
  editor = {Baltagi, Badi H.},
  year = {2003},
  keywords = {econometrics,Monte Carlo test methods,multivariate regression models,nuisance parameters,randomized test procedure},
  pages = {494--519},
  file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\8RUIDBI8\\summary.html:text/html}
}

@article{dwass_modified_1957,
  title = {Modified {{Randomization Tests}} for {{Nonparametric Hypotheses}}},
  volume = {28},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177707045},
  abstract = {Suppose X1,$\cdots$,Xm,Y1,$\cdots$,YnX\_1, $\backslash$cdots, X\_m, Y\_1, $\backslash$cdots, Y\_n are m+n=Nm + n = N independent random variables, the XX's identically distributed and the YY's identically distributed, each with a continuous cdf. Let z=(z1,$\cdots$,zm,zm+1,$\cdots$,zN)=(x1,$\cdots$,xm,y1,$\cdots$,yn)z = (z\_1, $\backslash$cdots, z\_m, z\_\{m + 1\}, $\backslash$cdots, z\_N) = (x\_1, $\backslash$cdots, x\_m, y\_1, $\backslash$cdots, y\_n) represent an observation on the NN random variables and let u(z)=(1/m)m$\sum$i=1zi-(1/n)N$\sum$i=m+1zi=ˉx-ˉyu(z) = (1/m) $\backslash$sum\^m\_\{i = 1\} z\_i - (1/n) $\backslash$sum\^N\_\{i = m + 1\} z\_i = $\backslash$bar x - $\backslash$bar y. Consider the r=N!Nr = N! N-tuples obtained from (z1,$\cdots$,zN)(z\_1, $\backslash$cdots, z\_N) by making all permutations of the indices (1,$\cdots$,N)(1, $\backslash$cdots, N). Since we assume continuous cdf's, then with probability one, these rNr N-tuples will be distinct. Denote them by z(1),$\cdots$,z(r)z\^\{(1)\}, $\backslash$cdots, z\^\{(r)\}, and suppose that they have been ordered so that u(z(1)$\geqq\cdots\geqq$u(z(r))u(z\^\{(1)\} $\backslash$geqq $\backslash$cdots $\backslash$geqq u(z\^\{(r)\}). Notice that since ˉx-ˉy=(1/m)N$\sum$i=1zi-(N/m)ˉy=(N/n)ˉx-(1/n)N$\sum$i=1zi,$\backslash$bar x - $\backslash$bar y = (1/m) $\backslash$sum\^N\_\{i = 1\} z\_i - (N/m)$\backslash$bar y = (N/n)$\backslash$bar x - (1/n) $\backslash$sum\^N\_\{i = 1\} z\_i, the same ordering can be induced by choosing u(z)=cˉxu(z) = c$\backslash$bar x or u(z)=-cˉyu(z) = - c$\backslash$bar y for any c$>$0c $>$ 0. Assuming that the cdf's of X1,Y1X\_1, Y\_1 are of the form F(x),F(x-$\Delta$)F(x), F(x - $\backslash$Delta) respectively, Pitman [2] suggested essentially the following test of the hypothesis H${'}$H' that $\Delta$=0$\backslash$Delta = 0. Select a set of k(k$>$0)k (k $>$ 0) integers i1,$\cdots$,ik,(1$\leqq$i1$<$$\cdots$$<$ik$\leqq$r)i\_1, $\backslash$cdots, i\_k, (1 $\backslash$leqq i\_1 $<$ $\backslash$cdots $<$ i\_k $\backslash$leqq r). If the observed zz is one of the points z(i1),$\cdots$,z(ik)z\^\{(i\_1)\}, $\backslash$cdots, z\^\{(i\_k)\}, reject H${'}$H', otherwise accept. When H${'}$H' is true, the type one error does not depend on the specific form of the distribution of the XX's and the YY's and is in fact equal to k/rk/r. The choice of the rejection set i1,$\cdots$,iki\_1, $\backslash$cdots, i\_k should depend on the alternative hypothesis. For instance, if the experimenter wants protection against the alternative that the "XX's tend to be larger than the YY's," then the labels 1,$\cdots$,k1, $\backslash$cdots, k might be reasonable. For the alternative that the "XX's tend to be smaller than the YY's" the analogous procedure is to use the other tail, r-k+1,$\cdots$,rr - k + 1, $\backslash$cdots, r. Against both alternatives, a two-tail procedure could be used. Lehmann and Stein have shown in [1] that in the class of all tests (of size $\alpha$=k/r$\backslash$alpha = k/r) of the hypothesis H:the distribution ofX1$\cdots$,Xm,Y1,$\cdots$,Ynis invariant under all permutations,H: $\backslash$text\{the distribution of\} X\_1 $\backslash$cdots, X\_m, Y\_1, $\backslash$cdots, Y\_n $\backslash$text\{is invariant under all permutations\}, the single-tail test based on 1,$\cdots$,k1, $\backslash$cdots, k is uniformly most powerful against the alternatives that F1F\_1 is an N(\texttheta,$\sigma$)N($\backslash$theta, $\backslash$sigma) cdf, F2F\_2 is an N(\texttheta+$\Delta$,$\sigma$)N($\backslash$theta + $\backslash$Delta, $\backslash$sigma) cdf, $\Delta$$<$0$\backslash$Delta $<$ 0; the test based on r-k+1,$\cdots$,rr - k + 1, $\backslash$cdots, r is uniformly most powerful for $\Delta>$0$\backslash$Delta $>$ 0. A practical shortcoming of this procedure is the great difficulty in enumerating the points z(i)z\^\{(i)\} and the evaluation of u(z(i))u(z\^\{(i)\}) for each of them. For instance, even after eliminating those permutations which always give the same value of uu, then for sample sizes m=n=5m = n = 5, there are (105)=252$\backslash$binom\{10\}\{5\} = 252 permutations to examine, and for sample sizes m=n=10m = n = 10, there are (2010)=184,765$\backslash$binom\{20\}\{10\} = 184,765 permutations to examine. In the following section, we propose the almost obvious procedure of examining a "random sample" of permutations and making the decision to accept or reject HH on the basis of those permutations only. Bounds are determined for the ratio of the power of the original procedure to the modified one. Some numerical values of these bounds are given in Table 1. The bounds there listed correspond to tests which in both original and modified form have size $\alpha\backslash$alpha, and for which the modified test is based on a random sample of ss permutations drawn with replacement. These have been computed for a certain class of alternatives which is described below. For simplicity, we have restricted the main exposition to the two-sample problem. In Section 5, we point out extensions to the more general hypotheses of invariance studied in [1].},
  language = {EN},
  timestamp = {2016-08-01T22:10:42Z},
  number = {1},
  urldate = {2016-07-29},
  journal = {The Annals of Mathematical Statistics},
  author = {Dwass, Meyer},
  month = mar,
  year = {1957},
  pages = {181--187},
  file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\29HM4EVJ\\1177707045.html:text/html},
  mrnumber = {MR87280}
}

@article{barnard_comment_1963,
  title = {Comment on: "{{The Spectral Analysis}} of {{Point Processes}}" by {{M}}.{{S}}. {{Bartlett}}},
  volume = {25},
  issn = {0035-9246},
  abstract = {The spectral analysis of stationary point processes in one dimension is developed in some detail as a statistical method of analysis. The asymptotic sampling theory previously established by the author for a class of doubly stochastic Poisson processes is shown to apply also for a class of clustering processes, the spectra of which are contrasted with those of renewal processes. The analysis is given for two illustrative examples, one an artificial Poisson process, the other of some traffic data. In addition to testing the fit of a clustering model to the latter example, the analysis of these two examples is used where possible to check the validity of the sampling theory.},
  timestamp = {2016-08-01T22:10:32Z},
  number = {2},
  urldate = {2016-07-30},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  author = {Barnard, G. A.},
  year = {1963},
  pages = {294}
}

@book{wickham_scales:_2016,
  title = {Scales: {{Scale Functions}} for {{Visualization}}},
  timestamp = {2016-08-23T22:27:28Z},
  author = {Wickham, Hadley},
  year = {2016},
  note = {R package version 0.4.0}
}

@article{yang_xiang_generalized_2013,
  title = {Generalized {{Simulated Annealing}} for {{Efficient Global Optimization}}: The {{GenSA Package}} for {{R}}.},
  timestamp = {2016-08-23T22:27:30Z},
  journal = {The R Journal Volume 5/1, June 2013},
  author = {{Yang Xiang} and Gubian, Sylvain and Suomela, Brian and Hoeng, Julia},
  year = {2013}
}

@book{bendtsen_pso:_2012,
  title = {Pso: {{Particle Swarm Optimization}}},
  timestamp = {2016-08-23T22:27:24Z},
  author = {Bendtsen, Claus},
  year = {2012},
  note = {R package version 1.0.3}
}

@book{gilli_numerical_2011,
  address = {Waltham, MA, USA},
  title = {Numerical {{Methods}} and {{Optimization}} in {{Finance}}},
  timestamp = {2016-08-23T22:27:26Z},
  publisher = {{Academic Press}},
  author = {Gilli, Manfred and Maringer, Dietmar and Schumann, Enrico},
  year = {2011}
}

@article{dufour_exact_1996,
  title = {Exact Tests for Structural Change in First-Order Dynamic Models},
  volume = {70},
  issn = {0304-4076},
  timestamp = {2016-08-18T22:20:28Z},
  number = {1},
  urldate = {2016-08-18},
  journal = {Journal of Econometrics},
  author = {Dufour, Jean-Marie and Kiviet, Jan},
  year = {1996},
  pages = {39--68},
  file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\Q6H7Q9FV\\v_3a70_3ay_3a1996_3ai_3a1_3ap_3a39-68.html:text/html}
}

@book{wickham_devtools:_2016,
  title = {Devtools: {{Tools}} to Make Developing {{R}} Code Easier},
  timestamp = {2016-08-19T22:33:11Z},
  author = {Wickham, Hadley and Chang, Winston},
  year = {2016},
  note = {R package version 1.5.0.99}
}

@article{dufour_rank-robust_2016,
  title = {Rank-Robust {{Wald}}-Type Tests: A Regularization Approach},
  timestamp = {2016-08-21T23:44:56Z},
  author = {Dufour, Jean-Marie and Val{\'e}ry, Pascale},
  year = {2016}
}

@techreport{boudjellaba_simplified_1992,
  type = {Cahiers de recherche},
  title = {Simplified {{Conditions}} for {{Non}}-{{Causality Between Vectors}} in {{Multivariate Arma Models}}},
  abstract = {No abstract is available for this item.},
  timestamp = {2016-08-22T03:44:58Z},
  number = {9236},
  urldate = {2016-08-22},
  institution = {Universite de Montreal, Departement de sciences economiques},
  author = {Boudjellaba, H. and Dufour, J. M. and Roy, R.},
  year = {1992},
  keywords = {econometrics,ECONOMIC MODELS},
  file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\VJJNW7V7\\9236.html:text/html}
}

@incollection{gourieroux_size_2013,
  series = {Advances in Intelligent Systems and Computing},
  title = {Size {{Distortion}} in the {{Analysis}} of {{Volatility}} and {{Covolatility Effects}}},
  copyright = {\textcopyright{}2013 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-642-35442-7 978-3-642-35443-4},
  abstract = {Let us assume that {\^A} TA\^T$\backslash$hat\{A\}\_T is a consistent, asymptotically normal estimator of a matrix A (where T is the sample size), this paper shows that test statistics used in empirical work to test 1) the noninvertibility of A, i.e. det A = 0, 2) the positivite semi-definiteness A $>$ $>$ 0, have a different asymptotic distribution in the case where A = 0 than in the case where A $\not =$ 0. Moreover, the paper shows that an estimator of A constrained by symmetry or reduced rank has a different asymptotic distribution when A = 0 than when A $\not =$ 0. The implication is that inference procedures that use critical values equal to appropriate quantiles from the distribution when A $\not =$ 0 may be size distorted. The paper points out how the above statistical problems arise in standard models in Finance in the analysis of risk effects.A Monte Carlo study explores how the asymptotic results are reflected in finite sample.},
  language = {en},
  timestamp = {2016-08-22T03:47:28Z},
  number = {200},
  urldate = {2016-08-22},
  booktitle = {Uncertainty {{Analysis}} in {{Econometrics}} with {{Applications}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Gourieroux, Christian and Jasiak, Joann},
  editor = {Huynh, Van-Nam and Kreinovich, Vladik and Sriboonchitta, Songsak and Suriya, Komsan},
  year = {2013},
  keywords = {Artificial Intelligence (incl. Robotics),BEKK Model,Boundary,C10,C32,Computational Intelligence,econometrics,G10,G12,Identifiability,Invertibility Test,Multivariate Volatility,Risk Premium,Volatility Transmission},
  pages = {91--118},
  file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\6XVKM8PJ\\10.html:text/html},
  doi = {10.1007/978-3-642-35443-4_7}
}

@article{boudjellaba_testing_1992,
  title = {Testing {{Causality Between Two Vectors}} in {{Multivariate Autoregressive Moving Average Models}}},
  volume = {87},
  issn = {0162-1459},
  doi = {10.2307/2290645},
  abstract = {In the analysis of economic time series, a question often raised is whether a vector of variables causes another one in the sense of Granger. Most of the literature on this topic is concerned with bivariate relationships or uses finite-order autoregressive specifications. The purpose of this article is to develop a causality analysis in the sense of Granger for general vector autoregressive moving average (ARMA) models. We give a definition of Granger noncausality between vectors, which is a natural and simple extension of the notion of Granger noncausality between two variables. In our context, this definition is shown to be equivalent to a more complex definition proposed by Tjostheim. For the class of linear invertible processes, we derive a necessary and sufficient condition for noncausality between two vectors of variables when the latter do not necessarily include all the variables considered in the analysis. This result is then specialized to the class of stationary invertible ARMA processes. Further, relatively simple necessary and sufficient conditions are obtained for two important cases: (1) the case where the two vectors reduce to two variables inside a larger vector including other variables; and (2) the case where the two vectors embody all the variables considered. Test procedures for these necessary and sufficient conditions are discussed. Among other things, it is noted that the necessary and sufficient conditions for noncausality may involve singularities at which standard asymptotic regularity conditions do not hold. To deal with such situations, we propose a sequential approach that leads to bounds tests. Finally, the tests suggested are applied to Canadian money and income data. The tests are based on bivariate and trivariate models of changes in nominal income and two money stocks (M1 and M2). In contrast with the evidence based on bivariate models, we find from the trivariate model that money causes income unidirectionally.},
  timestamp = {2016-08-22T03:47:57Z},
  number = {420},
  urldate = {2016-08-22},
  journal = {Journal of the American Statistical Association},
  author = {Boudjellaba, Hafida and Dufour, Jean-Marie and Roy, Roch},
  year = {1992},
  pages = {1082--1090}
}

@article{mullen_continuous_2014,
  title = {Continuous Global Optimization in {{R}}},
  volume = {60},
  timestamp = {2016-08-22T21:39:06Z},
  number = {6},
  journal = {Journal of Statistical Software},
  author = {Mullen, Katharine M and {others}},
  year = {2014},
  pages = {1--45}
}

@article{scrucca_ga:_2013,
  title = {{{GA}}: {{A Package}} for {{Genetic Algorithms}} in {{R}}},
  volume = {53},
  timestamp = {2016-08-26T21:56:03Z},
  number = {4},
  journal = {Journal of Statistical Software},
  author = {Scrucca, Luca},
  year = {2013},
  pages = {1--37}
}

@article{scrucca_extensions_2016,
  title = {On Some Extensions to {{GA}} Package: Hybrid Optimisation, Parallelisation and Islands Evolution},
  timestamp = {2016-08-26T21:55:58Z},
  journal = {Submitted to R Journal},
  author = {Scrucca, Luca},
  year = {2016},
  note = {Pre-print available at arXiv}
}

@book{wuertz_funitroots:_2013,
  title = {{{fUnitRoots}}: {{Trends}} and {{Unit Roots}}},
  timestamp = {2016-09-03T21:16:16Z},
  author = {Wuertz, Diethelm and {et al.}},
  year = {2013},
  note = {R package version 3010.78}
}

@book{mersmann_microbenchmark:_2015,
  title = {Microbenchmark: {{Accurate Timing Functions}}},
  timestamp = {2016-08-23T22:27:18Z},
  author = {Mersmann, Olaf},
  year = {2015},
  note = {R package version 1.4-2.1}
}

@book{canty_boot:_2016,
  title = {Boot: {{Bootstrap R}} ({{S}}-{{Plus}}) {{Functions}}},
  timestamp = {2016-08-23T22:27:18Z},
  author = {Canty, Angelo and Ripley, B. D.},
  year = {2016},
  note = {R package version 1.3-18}
}

@book{davison_bootstrap_1997,
  address = {Cambridge},
  title = {Bootstrap {{Methods}} and {{Their Applications}}},
  timestamp = {2016-08-23T22:27:18Z},
  publisher = {{Cambridge University Press}},
  author = {Davison, A. C. and Hinkley, D. V.},
  year = {1997},
  note = {ISBN 0-521-57391-2}
}

@book{geyer_mcmc:_2015,
  title = {Mcmc: {{Markov Chain Monte Carlo}}},
  timestamp = {2016-08-23T22:27:18Z},
  author = {Geyer, Charles J. and Johnson, Leif T.},
  year = {2015},
  note = {R package version 0.9-4}
}

@article{martin_mcmcpack:_2011,
  title = {{{MCMCpack}}: {{Markov Chain Monte Carlo}} in {{R}}},
  volume = {42},
  timestamp = {2016-08-23T22:27:18Z},
  number = {9},
  journal = {Journal of Statistical Software},
  author = {Martin, Andrew D. and Quinn, Kevin M. and Park, Jong Hee},
  year = {2011},
  pages = {22}
}

@book{bornn_pawl:_2012,
  title = {{{PAWL}}: {{Implementation}} of the {{PAWL}} Algorithm},
  timestamp = {2016-08-23T22:27:18Z},
  author = {Bornn, Luke and Jacob, Pierre E.},
  year = {2012},
  note = {R package version 0.5}
}

@article{fernandez-i-marin_ggmcmc:_2016,
  title = {Ggmcmc: {{Analysis}} of {{MCMC Samples}} and {{Bayesian Inference}}},
  volume = {70},
  doi = {10.18637/jss.v070.i09},
  timestamp = {2016-08-23T22:27:18Z},
  number = {9},
  journal = {Journal of Statistical Software},
  author = {Fern{\'a}ndez-i-Mar{\'\i}n, Xavier},
  year = {2016},
  pages = {1--20}
}

@book{caffo_exactloglintest:_2013,
  title = {{{exactLoglinTest}}: {{Monte Carlo Exact Tests}} for {{Log}}-Linear Models},
  timestamp = {2016-08-23T22:27:18Z},
  author = {Caffo, Brian},
  year = {2013},
  note = {R package version 1.4.2}
}

@book{r_core_team_r:_2016,
  address = {Vienna, Austria},
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  timestamp = {2016-08-24T01:16:48Z},
  publisher = {{R Foundation for Statistical Computing}},
  author = {{R Core Team}},
  year = {2016}
}

@article{zambrano-bigiarini_model-independent_2013,
  title = {A Model-Independent {{Particle Swarm Optimisation}} Software for Model Calibration},
  volume = {43},
  timestamp = {2016-09-03T21:17:55Z},
  journal = {Environmental Modelling  Software},
  author = {Zambrano-Bigiarini, Mauricio and Rojas, Rodrigo},
  year = {2013},
  pages = {5--25}
}

@book{zambrano-bigiarini_hydropso:_2014,
  title = {{{hydroPSO}}: {{Particle Swarm Optimisation}}, with Focus on {{Environmental Models}}},
  timestamp = {2016-09-03T21:18:21Z},
  author = {Zambrano-Bigiarini, Mauricio and Rojas, Rodrigo},
  year = {2014},
  note = {R package version 0.3-4}
}

@book{ardia_deoptim:_2015,
  title = {{{DEoptim}}: {{Differential Evolution}} in {{R}}},
  timestamp = {2016-08-24T01:06:08Z},
  author = {Ardia, David and Mullen, Katharine M. and Peterson, Brian G. and Ulrich, Joshua},
  year = {2015},
  note = {version 2.2-3 
 = \{\{DEoptim\}: Differential Evolution in \{R\}\}}
}

@article{mullen_deoptim:_2011,
  title = {{{DEoptim}}: {{An R Package}} for {{Global Optimization}} by {{Differential Evolution}}},
  volume = {40},
  timestamp = {2016-08-24T01:15:40Z},
  number = {6},
  journal = {Journal of Statistical Software},
  author = {Mullen, Katharine and Ardia, David and Gil, David and Windover, Donald and Cline, James},
  year = {2011},
  note = {= \{\{DEoptim\}: An \{R\} Package for Global Optimization by Differential Evolution\}},
  pages = {1--26}
}

@article{ardia_differential_2011,
  title = {Differential {{Evolution}} with {{DEoptim}}: {{An Application}} to {{Non}}-{{Convex Portfolio Optimization}}},
  volume = {3},
  timestamp = {2016-08-24T01:12:34Z},
  number = {1},
  journal = {The R Journal},
  author = {Ardia, David and Boudt, Kris and Carl, Peter and Mullen, Katharine M. and Peterson, Brian G.},
  year = {2011},
  note = {= \{\{D\}ifferential \{E\}volution with \{DEoptim\}: An Application to Non-Convex Portfolio Optimization\}},
  pages = {27--34}
}

@article{ardia_jump-diffusion_2011,
  title = {Jump-{{Diffusion Calibration}} Using {{Differential Evolution}}},
  volume = {55},
  timestamp = {2016-08-24T01:06:55Z},
  journal = {Wilmott Magazine},
  author = {Ardia, David and Arango, Juan Ospina and Gomez, Norman Giraldo},
  year = {2011},
  note = {= \{\{J\}ump-Diffusion Calibration using \{D\}ifferential \{E\}volution\}},
  pages = {76--79}
}

@book{price_differential_2006,
  series = {Natural Computing},
  title = {Differential {{Evolution}} - {{A Practical Approach}} to {{Global Optimization}}},
  timestamp = {2016-09-03T21:16:46Z},
  publisher = {{Springer-Verlag}},
  author = {Price, Kenneth V. and Storn, Rainer M. and Lampinen, Jouni A.},
  month = jan,
  year = {2006},
  note = {ISBN 540209506}
}

@book{clayden_soma:_2014,
  title = {Soma: {{General}}-{{Purpose Optimisation With}} the {{Self}}-{{Organising Migrating Algorithm}}},
  timestamp = {2016-09-04T20:01:29Z},
  author = {Clayden, Jon and Zelinka, Ivan},
  year = {2014},
  note = {R package version 1.1.1}
}

@book{bergmeir_continuous_2012,
  title = {Continuous {{Optimization}} Using {{Memetic Algorithms}} with {{Local Search Chains}} ({{MA}}-{{LS}}-{{Chains}}) in {{R}}},
  timestamp = {2016-08-24T01:06:19Z},
  author = {Bergmeir, Christoph and Molina, Daniel and Be{\'n}itez, Jo{\'s}e M.},
  year = {2012},
  note = {R package version 0.1 
 = \{Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R\}}
}

@book{trautmann_cmaes:_2011,
  title = {Cmaes: {{Covariance Matrix Adapting Evolutionary Strategy}}},
  timestamp = {2016-08-24T01:15:51Z},
  author = {Trautmann, Heike and Mersmann, Olaf and Arnu, David},
  year = {2011},
  note = {R package version 1.0-11 
 = \{cmaes: Covariance Matrix Adapting Evolutionary Strategy\}}
}

@book{ghalanos_parma:_2015,
  title = {Parma: Portfolio Allocation and Risk Management Applications},
  timestamp = {2016-08-24T01:16:40Z},
  author = {Ghalanos, Alexios and Pfaff, Bernhard},
  year = {2015},
  note = {R package version 1.5-2. 
 = \{parma: portfolio allocation and risk management applications.\}}
}

@book{burns_burstmisc:_2016,
  title = {{{BurStMisc}}: {{Burns Statistics Miscellaneous}}},
  timestamp = {2016-08-24T01:06:33Z},
  author = {Burns, Pat},
  year = {2016},
  note = {R package version 1.1 
 = \{BurStMisc: Burns Statistics Miscellaneous\}}
}

@article{satman_machine_2013,
  title = {Machine {{Coded Genetic Algorithms For Real Parameter Optimization Problems}}},
  volume = {26},
  timestamp = {2016-08-26T21:56:00Z},
  number = {1},
  journal = {Gazi University Journal of Science},
  author = {Satman, Mehmet Hakan},
  year = {2013},
  note = {= \{Machine Coded Genetic Algorithms For Real Parameter Optimization Problems\}},
  pages = {85--95}
}

@book{ciupke_psoptim:_2016,
  title = {Psoptim: {{Particle Swarm Optimization}}},
  timestamp = {2016-08-24T01:15:04Z},
  author = {Ciupke, Krzysztof},
  year = {2016},
  note = {R package version 1.0 
 = \{psoptim: Particle Swarm Optimization\}}
}

@article{fisher_fiducial_1935,
  title = {The Fiducial Argument in Statistical Inference},
  doi = {10.1111/j.1469-1809.1935.tb02120.x},
  timestamp = {2016-08-24T21:16:29Z},
  journal = {Annals of Eugenics.},
  author = {Fisher, R. A.},
  year = {1935},
  pages = {391--398}
}

@article{fisher_asymptotic_1941,
  title = {The Asymptotic Approach to {{Behrens}}' Integral, with Further Tables for the d Test of Significance},
  volume = {11},
  doi = {10.1111/j.1469-1809.1941.tb02281.x},
  timestamp = {2016-08-24T21:16:30Z},
  journal = {Annals of Eugenics.},
  author = {Fisher, R. A.},
  year = {1941},
  pages = {141--172}
}

@article{behrens_beitrag_1929,
  title = {Ein {{Beitrag}} Zur {{Fehlerberechnung}} Bei Wenigen {{Beobachtungen}}},
  volume = {68},
  timestamp = {2016-08-24T21:16:30Z},
  journal = {Landwirtschaftliche Jahrbucher.},
  author = {Behrens, W. U.},
  year = {1929},
  pages = {807--837}
}

@article{welch_significance_1938,
  title = {The Significance or the Difference between Two Means When the Population Variances Are Unequal},
  volume = {29},
  doi = {10.2307/2332010},
  timestamp = {2016-08-24T21:16:30Z},
  journal = {Biometrika.},
  author = {Welch, B. L.},
  year = {1938},
  pages = {350--362}
}

@article{welch_generalization_1947,
  title = {The Generalization of '{{Student}}'s' Problem When Several Different Population Variances Are Involved},
  volume = {34},
  doi = {10.2307/2332510},
  timestamp = {2016-08-24T21:16:30Z},
  journal = {Biometrika.},
  author = {Welch, B. L.},
  year = {1947},
  pages = {28--35}
}

@inproceedings{eberhart_new_1995,
  title = {A New Optimizer Using Particle Swarm Theory},
  volume = {1},
  timestamp = {2016-08-24T22:53:28Z},
  booktitle = {Proceedings of the Sixth International Symposium on Micro Machine and Human Science},
  publisher = {{New York, NY}},
  author = {Eberhart, Russ C and Kennedy, James and {others}},
  year = {1995},
  pages = {39--43}
}

@article{kirkpatrick_optimization_1984,
  title = {Optimization by Simulated Annealing: {{Quantitative}} Studies},
  volume = {34},
  timestamp = {2016-08-24T22:53:29Z},
  number = {5-6},
  journal = {Journal of statistical physics},
  author = {Kirkpatrick, Scott},
  year = {1984},
  pages = {975--986}
}

@article{holland_adaptation_1992,
  title = {Adaptation in Natural and Artificial Systems. 1975},
  timestamp = {2016-08-24T22:53:29Z},
  journal = {Ann Arbor, MI: University of Michigan Press and},
  author = {Holland, John H},
  year = {1992}
}

@article{dufour_exact_2001,
  title = {Exact {{Nonparametric Two}}-{{Sample Homogeneity Tests}} for {{Possibly Discrete Distributions}}.},
  timestamp = {2016-08-25T02:34:10Z},
  author = {Dufour, Jean-Marie and Farhat, Abdeljelil},
  year = {2001}
}

@article{david_a._dickey_determining_1987,
  title = {Determining the {{Order}} of {{Differencing}} in {{Autoregressive Processes}}},
  volume = {5},
  issn = {07350015},
  abstract = {One way of handling nonstationarity in time series is to compute first differences and fit a model to the differenced series unless the differenced series also looks nonstationary. In that case, second- or higher-order differencing is done. To decide if the current degree of differencing is sufficient, one can look at the autocorrelation function for slow decay. A formal statistical test for the need to difference further is available if one is willing to assume that at most one more difference will render the series stationary. In this article, we present a proper sequence of statistical tests that allows the practitioner to handle cases in which a high order of differencing may be needed. The proper sequence is not the traditional sequence, which begins with a test for a single unit root.},
  timestamp = {2016-08-25T20:17:00Z},
  number = {4},
  journal = {Journal of Business  Economic Statistics},
  author = {David A. Dickey, Sastry G. Pantula},
  year = {1987},
  pages = {455--461}
}

@article{pantula_testing_1989,
  title = {Testing for {{Unit Roots}} in {{Time Series Data}}},
  volume = {5},
  issn = {02664666, 14694360},
  abstract = {Let Yt satisfy the stochastic difference equation Yt=$\Sigma$ j=1 p$\alpha$ jYt-j+$\Sigma$ j=1 q\texttheta{} jet-j+et, for t = 1,2,..., where et are independent and identically distributed random variables with mean zero and variance $\sigma$ 2 and the initial conditions (Y-p+1,...,Y0) are fixed constants. It is assumed that the process is invertible and that the true, but unknown, roots m1,m2,...,mp of mp-$\Sigma$ j=1 p$\alpha$ jmp-j=0 satisfy the hypothesis Hd: m1=...=md=1 and |m\textsubscript{j}|$<$1 for j = d + 1,...,p. We present a reparameterization of the model for Yt that is convenient for testing the hypothesis Hd. We consider the asymptotic properties of (i) a likelihood ratio type "F-statistic" for testing the hypothesis Hd, (ii) a likelihood ratio type t-statistic for testing the hypothesis Hd against the alternative Hd-1. Using these asymptotic results, we obtain two sequential testing procedures that are asymptotically consistent.},
  timestamp = {2016-08-25T20:17:01Z},
  number = {2},
  journal = {Econometric Theory},
  author = {Pantula, Sastry G.},
  year = {1989},
  pages = {256--271}
}

@book{fuller_introduction_1976,
  address = {New York, NY},
  title = {Introduction to {{Statistical Time Series}}},
  timestamp = {2016-08-25T20:27:05Z},
  publisher = {{John Wiley}},
  author = {Fuller, W. A.},
  year = {1976}
}

@article{cerny_thermodynamical_1985,
  title = {Thermodynamical Approach to the Traveling Salesman Problem: {{An}} Efficient Simulation Algorithm},
  volume = {45},
  issn = {0022-3239, 1573-2878},
  shorttitle = {Thermodynamical Approach to the Traveling Salesman Problem},
  doi = {10.1007/BF00940812},
  abstract = {We present a Monte Carlo algorithm to find approximate solutions of the traveling salesman problem. The algorithm generates randomly the permutations of the stations of the traveling salesman trip, with probability depending on the length of the corresponding route. Reasoning by analogy with statistical thermodynamics, we use the probability given by the Boltzmann-Gibbs distribution. Surprisingly enough, using this simple algorithm, one can get very close to the optimal solution of the problem or even find the true optimum. We demonstrate this on several examples.We conjecture that the analogy with thermodynamics can offer a new insight into optimization problems and can suggest efficient algorithms for solving them.},
  language = {en},
  timestamp = {2016-08-26T15:47:58Z},
  number = {1},
  urldate = {2016-08-26},
  journal = {Journal of Optimization Theory and Applications},
  author = {{\v C}ern{\'y}, V.},
  year = {1985},
  pages = {41--51},
  file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\78AP9FFF\\10.html:text/html}
}

@article{kirkpatrick_optimization_1983,
  title = {Optimization by Simulated Annealing},
  volume = {220},
  issn = {0036-8075},
  doi = {10.1126/science.220.4598.671},
  abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
  language = {eng},
  timestamp = {2016-08-26T15:37:21Z},
  number = {4598},
  journal = {Science (New York, N.Y.)},
  author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
  month = may,
  year = {1983},
  pages = {671--680},
  pmid = {17813860}
}

@inproceedings{shi_modified_1998,
  title = {A Modified Particle Swarm Optimizer},
  timestamp = {2016-08-26T16:56:45Z},
  booktitle = {Evolutionary {{Computation Proceedings}}, 1998. {{IEEE World Congress}} on {{Computational Intelligence}}., {{The}} 1998 {{IEEE International Conference}} On},
  publisher = {{IEEE}},
  author = {Shi, Yuhui and Eberhart, Russell},
  year = {1998},
  pages = {69--73}
}

@book{willighagen_genalg:_2015,
  title = {Genalg: {{R Based Genetic Algorithm}}},
  timestamp = {2016-08-26T21:55:51Z},
  author = {Willighagen, Egon and Ballings, Michel},
  year = {2015},
  note = {R package version 0.2.0}
}

@book{wickham_ggplot2:_2009,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  isbn = {978-0-387-98140-6},
  timestamp = {2016-08-26T22:07:29Z},
  publisher = {{Springer-Verlag New York}},
  author = {Wickham, Hadley},
  year = {2009}
}

@techreport{banerjee_co-integration_1993,
  type = {OUP Catalogue},
  title = {Co-Integration, {{Error Correction}}, and the {{Econometric Analysis}} of {{Non}}-{{Stationary Data}}},
  abstract = {This book provides a wide-ranging account of the literature on co-integration and the modelling of integrated processes (those which accumulate the effects of past shocks). Data series which display integrated behaviour are common in economics, although techniques appropriate to analysing such data are of recent origin and there are few existing expositions of the literature. This book focuses on the exploration of relationships among integrated data series and the exploitation of these relationships in dynamic econometric modelling. The concepts of co-integration and error-correction models are fundamental components of the modelling strategy. This area of time-series econometrics has grown in importance over the past decade and is of interest to econometric theorists and applied econometricians alike. By explaining the important concepts informally, but also presenting them formally, the book bridges the gap between purely descriptive and purely theoretical accounts of the literature. The asymptotic theory of integrated processes is described and the tools provided by this theory are used to develop the distributions of estimators and test statistics. Practical modelling advice, and the use of techniques for systems estimation, are also emphasized. A knowledge of econometrics, statistics, and matrix algebra at the level of a final-year undergraduate or first-year undergraduate course in econometrics is sufficient for most of the book. Other mathematical tools are described as they occur.},
  timestamp = {2016-08-27T01:00:14Z},
  urldate = {2016-08-27},
  institution = {Oxford University Press},
  author = {Banerjee, Anindya and Dolado, Juan and Galbraith, John and Hendry, David},
  year = {1993},
  file = {RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\BW99JKBE\\9780198288107.html:text/html}
}

@book{zeileis_dynlm:_2014,
  title = {Dynlm: {{Dynamic Linear Regression}}},
  timestamp = {2016-08-28T01:51:00Z},
  author = {Zeileis, Achim},
  year = {2014},
  note = {R package version 0.3-3}
}

@article{dickey_distribution_1979,
  title = {Distribution of the {{Estimators}} for {{Autoregressive Time Series With}} a {{Unit Root}}},
  volume = {74},
  issn = {0162-1459},
  doi = {10.2307/2286348},
  abstract = {Let n observations Y\textsubscript{1}, Y\textsubscript{2}, ..., Y\textsubscript{n} be generated by the model Y\textsubscript{t} = $\rho$ Y\textsubscript{t - 1} + e\textsubscript{t}, where Y\textsubscript{0} is a fixed constant and \{e\vphantom\}\textsubscript{t}\vphantom\{\}\textsubscript{t = 1}\textsuperscript{n} is a sequence of independent normal random variables with mean 0 and variance $\sigma$\textsuperscript{2}. Properties of the regression estimator of $\rho$ are obtained under the assumption that $\rho$ = $\pm$ 1. Representations for the limit distributions of the estimator of $\rho$ and of the regression t test are derived. The estimator of $\rho$ and the regression t test furnish methods of testing the hypothesis that $\rho$ = 1.},
  timestamp = {2016-08-28T02:40:29Z},
  number = {366},
  urldate = {2016-08-28},
  journal = {Journal of the American Statistical Association},
  author = {Dickey, David A. and Fuller, Wayne A.},
  year = {1979},
  pages = {427--431}
}

@article{smirnov_table_1948,
  title = {Table for Estimating the Goodness of Fit of Empirical Distributions},
  volume = {19},
  timestamp = {2016-09-03T18:26:58Z},
  number = {2},
  journal = {The annals of mathematical statistics},
  author = {Smirnov, Nickolay},
  year = {1948},
  pages = {279--281}
}

@article{smirnoff_sur_1939,
  title = {Sur Les {\'E}carts de La Courbe de Distribution Empirique},
  volume = {48},
  timestamp = {2016-09-03T18:29:17Z},
  number = {1},
  journal = {Matematicheskii Sbornik},
  author = {Smirnoff, N},
  year = {1939},
  pages = {3--26}
}

@book{venables_modern_2002,
  address = {New York},
  edition = {Fourth},
  title = {Modern {{Applied Statistics}} with {{S}}},
  timestamp = {2016-09-06T05:02:47Z},
  publisher = {{Springer}},
  author = {Venables, W. N. and Ripley, B. D.},
  year = {2002},
  note = {ISBN 0-387-95457-0}
}

@book{wickham_roxygen2:_2015,
  title = {Roxygen2: {{In}}-{{Source Documentation}} for {{R}}},
  timestamp = {2016-09-06T21:00:09Z},
  author = {Wickham, Hadley and Danenberg, Peter and Eugster, Manuel},
  year = {2015},
  note = {R package version 5.0.1}
}

@article{Wagner2008,
  title = {On {{PPP}}, Unit Roots and Panels},
  volume = {35},
  issn = {1435-8921},
  doi = {10.1007/s00181-007-0156-z},
  abstract = {In this paper we use a combination of time series unit root and cointegration analysis and the Bai and Ng (Econometrica 72:1127--1187, 2004) factor model approach to assess the purchasing power parity hypothesis for four real exchange rate panels. Our main findings are twofold: First, we find robust evidence for nonstationary common components in the real exchange rate panels and hence no evidence for PPP. Second, the presence of nonstationary common components is consistent with rejections of the unit root null hypothesis when applying a battery of first and second generation panel unit root tests, which are known to be adversely affected in the presence of common nonstationary components.},
  timestamp = {2017-02-16T05:52:58Z},
  number = {2},
  journal = {Empirical Economics},
  author = {Wagner, Martin},
  year = {2008},
  pages = {229--249}
}

@article{bai_estimating_2004,
  title = {Estimating Cross-Section Common Stochastic Trends in Nonstationary Panel Data},
  volume = {122},
  issn = {0304-4076},
  doi = {10.1016/j.jeconom.2003.10.022},
  abstract = {This paper studies large-dimension factor models with nonstationary dynamic factors, also referred to as cross-section common stochastic trends. We consider the problem of estimating the dimension of the common stochastic trends and the stochastic trends themselves. We derive the rates of convergence and the limiting distributions for the estimated common trends and for the estimated loading coefficients. Generalized dynamic factor models with nonstationary factors are also considered. Cointegration among the factors is permitted. The method is applied to the study of employment fluctuations across 60 industries for the U.S. We examine the hypothesis that these fluctuations can be explained by a small number of aggregate factors. We also test whether some observable macroeconomic variables are the underlying factors.},
  timestamp = {2017-02-16T05:54:18Z},
  number = {1},
  urldate = {2017-02-16},
  journal = {Journal of Econometrics},
  author = {Bai, Jushan},
  month = sep,
  year = {2004},
  keywords = {Common-stochastic trends,Dynamic factors,Generalized dynamic factor models,Nonstationary panel data,Principal components},
  pages = {137--183},
  file = {ScienceDirect Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\UBMRU6IS\\S0304407603002720.html:text/html}
}

@incollection{breitung_local_2001,
  series = {Advances in Econometrics},
  title = {The Local Power of Some Unit Root Tests for Panel Data},
  volume = {15},
  timestamp = {2017-02-16T05:55:23Z},
  number = {15},
  urldate = {2017-02-16},
  booktitle = {Nonstationary {{Panels}}, {{Panel Cointegration}}, and {{Dynamic Panels}}},
  publisher = {{Emerald Group Publishing Limited}},
  author = {Breitung, J{\"o}rg},
  month = jan,
  year = {2001},
  pages = {161--177},
  file = {Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\42CZ6RP3\\S0731-9053(00)15006-6.html:text/html},
  doi = {10.1016/S0731-9053(00)15006-6}
}

@article{levin_unit_2002,
  title = {Unit Root Tests in Panel Data: Asymptotic and Finite-Sample Properties},
  volume = {108},
  issn = {0304-4076},
  shorttitle = {Unit Root Tests in Panel Data},
  doi = {10.1016/S0304-4076(01)00098-7},
  abstract = {We consider pooling cross-section time series data for testing the unit root hypothesis. The degree of persistence in individual regression error, the intercept and trend coefficient are allowed to vary freely across individuals. As both the cross-section and time series dimensions of the panel grow large, the pooled t-statistic has a limiting normal distribution that depends on the regression specification but is free from nuisance parameters. Monte Carlo simulations indicate that the asymptotic results provide a good approximation to the test statistics in panels of moderate size, and that the power of the panel-based unit root test is dramatically higher, compared to performing a separate unit root test for each individual time series.},
  timestamp = {2017-02-16T05:55:26Z},
  number = {1},
  urldate = {2017-02-16},
  journal = {Journal of Econometrics},
  author = {Levin, Andrew and Lin, Chien-Fu and James Chu, Chia-Shang},
  month = may,
  year = {2002},
  keywords = {ADF regression,Nonstationary panel,Panel unit root test,Pooled t-statistics},
  pages = {1--24},
  file = {ScienceDirect Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\8CCV7DRJ\\S0304407601000987.html:text/html}
}

@article{oconnell_overvaluation_1998,
  title = {The Overvaluation of Purchasing Power Parity},
  volume = {44},
  issn = {0022-1996},
  doi = {10.1016/S0022-1996(97)00017-2},
  abstract = {Recent panel studies of purchasing power parity have reported strong evidence of mean-reversion in real exchange rates. However, these studies fail to control for cross-sectional dependence in the data. This failure has dramatic consequences, raising the significance level of tests with a nominal size of 5 percent to as much as 50 percent. It is shown in this paper that, controlling for cross-sectional dependence, no evidence against the random walk null can be found in panels of up to 64 real exchange rates. This finding cannot be attributed to low power, as there is ample power in panels of this size to reject the unit-root null.},
  timestamp = {2017-02-16T05:56:27Z},
  number = {1},
  urldate = {2017-02-16},
  journal = {Journal of International Economics},
  author = {O'Connell, Paul G. J.},
  month = feb,
  year = {1998},
  keywords = {Mean-reversion,Purchasing power parity,Real exchange rate},
  pages = {1--19},
  file = {ScienceDirect Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\88X5W5EU\\S0022199697000172.html:text/html}
}

@article{chang_nonlinear_2002,
  series = {Long memory and nonlinear time series},
  title = {Nonlinear {{IV}} Unit Root Tests in Panels with Cross-Sectional Dependency},
  volume = {110},
  issn = {0304-4076},
  doi = {10.1016/S0304-4076(02)00095-7},
  abstract = {We propose a unit root test for panels with cross-sectional dependency. We allow general dependency structure among the innovations that generate data for each of the cross-sectional units. Each unit may have different sample size, and therefore unbalanced panels are also permitted in our framework. Yet, the test is asymptotically normal, and does not require any tabulation of the critical values. Our test is based on nonlinear IV estimation of the usual augmented Dickey\textendash{}Fuller type regression for each cross-sectional unit, using as instruments nonlinear transformations of the lagged levels. The actual test statistic is simply defined as a standardized sum of individual IV t-ratios. We show in the paper that such a standardized sum of individual IV t-ratios has limit normal distribution as long as the panels have large individual time series observations and are asymptotically balanced in a very weak sense. We may have the number of cross-sectional units arbitrarily small or large. In particular, the usual sequential asymptotics, upon which most of the available asymptotic theories for panel unit root models heavily rely, are not required. Finite sample performance of our test is examined via a set of simulations, and compared with those of other commonly used panel unit root tests. Our test generally performs better than the existing tests in terms of both finite sample sizes and powers. We apply our nonlinear IV method to test for the purchasing power parity hypothesis in panels.},
  timestamp = {2017-02-16T05:57:06Z},
  number = {2},
  urldate = {2017-02-16},
  journal = {Journal of Econometrics},
  author = {Chang, Yoosoon},
  month = oct,
  year = {2002},
  keywords = {Average IV t-ratio statistics,Nonlinear instruments,Panels with cross-sectional dependency,Unit root tests},
  pages = {261--292},
  file = {ScienceDirect Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\T9XEKNQ7\\S0304407602000957.html:text/html}
}

@article{choi_unit_2001,
  title = {Unit Root Tests for Panel Data},
  volume = {20},
  issn = {0261-5606},
  doi = {10.1016/S0261-5606(00)00048-6},
  abstract = {This paper develops unit root tests for panel data. These tests are devised under more general assumptions than the tests previously proposed. First, the number of groups in the panel data is assumed to be either finite or infinite. Second, each group is assumed to have different types of nonstochastic and stochastic components. Third, the time series spans for the groups are assumed to be all different. Fourth, the alternative where some groups have a unit root and others do not can be dealt with by the tests. The tests can also be used for the null of stationarity and for cointegration, once relevant changes are made in the model, hypotheses, assumptions and underlying tests. The main idea for our unit root tests is to combine p-values from a unit root test applied to each group in the panel data. Combining p-values to formulate tests is a common practice in meta-analysis. This paper also reports the finite sample performance of our combination unit root tests and Im et al.'s [Mimeo (1995)] t-bar test. The results show that most of the combination tests are more powerful than the t-bar test in finite samples. Application of the combination unit root tests to the post-Bretton Woods US real exchange rate data provides some evidence in favor of the PPP hypothesis.},
  timestamp = {2017-02-16T05:57:09Z},
  number = {2},
  urldate = {2017-02-16},
  journal = {Journal of International Money and Finance},
  author = {Choi, In},
  month = apr,
  year = {2001},
  keywords = {Meta-analysis,Panel data,Purchasing power parity,Unit root test},
  pages = {249--272},
  file = {ScienceDirect Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\ZXQB6FTA\\S0261560600000486.html:text/html}
}

@article{moon_testing_2004,
  title = {Testing for a Unit Root in Panels with Dynamic Factors},
  volume = {122},
  issn = {0304-4076},
  doi = {10.1016/j.jeconom.2003.10.020},
  abstract = {This paper studies testing for a unit root for large n and T panels in which the cross-sectional units are correlated. To model this cross-sectional correlation, we assume that the data are generated by an unknown number of unobservable common factors. We propose unit root tests in this environment and derive their (Gaussian) asymptotic distribution under the null hypothesis of a unit root and local alternatives. We show that these tests have significant asymptotic power when the model has no incidental trends. However, when there are incidental trends in the model and it is necessary to remove heterogeneous deterministic components, we show that these tests have no power against the same local alternatives. Through Monte Carlo simulations, we provide evidence on the finite sample properties of these new tests.},
  timestamp = {2017-02-16T06:04:10Z},
  number = {1},
  urldate = {2017-02-16},
  journal = {Journal of Econometrics},
  author = {Moon, Hyungsik Roger and Perron, Benoit},
  month = sep,
  year = {2004},
  keywords = {Cross-sectional dependence,Factor models,Incidental trends,Local-to-unity asymptotics,Panel data,Unit root},
  pages = {81--126},
  file = {ScienceDirect Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\2RU64U4F\\S0304407603002707.html:text/html}
}

@article{maddala_comparative_1999,
  title = {A {{Comparative Study}} of {{Unit Root Tests}} with {{Panel Data}} and a {{New Simple Test}}},
  volume = {61},
  issn = {1468-0084},
  doi = {10.1111/1468-0084.0610s1631},
  abstract = {The panel data unit root test suggested by Levin and Lin (LL) has been widely used in several applications, notably in papers on tests of the purchasing power parity hypothesis. This test is based on a very restrictive hypothesis which is rarely ever of interest in practice. The Im\textendash{}Pesaran\textendash{}Shin (IPS) test relaxes the restrictive assumption of the LL test. This paper argues that although the IPS test has been offered as a generalization of the LL test, it is best viewed as a test for summarizing the evidence from a number of independent tests of the sample hypothesis. This problem has a long statistical history going back to R. A. Fisher. This paper suggests the Fisher test as a panel data unit root test, compares it with the LL and IPS tests, and the Bonferroni bounds test which is valid for correlated tests. Overall, the evidence points to the Fisher test with bootstrap-based critical values as the preferred choice. We also suggest the use of the Fisher test for testing stationarity as the null and also in testing for cointegration in panel data.},
  language = {en},
  timestamp = {2017-02-16T06:05:40Z},
  number = {S1},
  urldate = {2017-02-16},
  journal = {Oxford Bulletin of Economics and Statistics},
  author = {Maddala, G. S. and Wu, Shaowen},
  month = nov,
  year = {1999},
  pages = {631--652},
  file = {Full Text PDF:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\DSVUIAJJ\\Maddala and Wu - 1999 - A Comparative Study of Unit Root Tests with Panel .pdf:application/pdf;Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\6VRPWVCM\\abstract.html:text/html}
}

@article{lyhagen_why_2008,
  title = {Why Not Use Standard Panel Unit Root Test for Testing {{PPP}}},
  volume = {3},
  abstract = {In this paper we show the consequences of applying a panel unit root test that assumes independence between the cross-sections when testing for a purchasing power parity relationship. The distribution of the tests investigated, including the IPS test of Im et al (2003), are influenced by a common stochastic trend which is usually not accounted for. The result is that the empirical size tends to one with the number of cross-sections. Hence, it is of crucial importance to account for this cross-sectional dependency.},
  timestamp = {2017-02-16T06:10:39Z},
  number = {26},
  urldate = {2017-02-16},
  journal = {Economics Bulletin},
  author = {Lyhagen, Johan},
  year = {2008},
  pages = {1--11},
  file = {RePEc PDF:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\2I2SKQ7Q\\Lyhagen - 2008 - Why not use standard panel unit root test for test.pdf:application/pdf;RePEc Snapshot:C\:\\Users\\Julien\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\6kppnqrd.default\\zotero\\storage\\QM8NQCB7\\eb-07c20098.html:text/html}
}


